{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99046ca",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6a1f6",
   "metadata": {},
   "source": [
    "## Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.\n",
    "Eigenvalues and eigenvectors are properties of square matrices that arise from solving the equation:\n",
    "\n",
    "𝐴\n",
    "𝑣\n",
    "=\n",
    "𝜆\n",
    "𝑣\n",
    "Av=λv\n",
    "\n",
    "where \n",
    "𝐴\n",
    "A is a square matrix, \n",
    "𝑣\n",
    "v is a non-zero vector (the eigenvector), and \n",
    "𝜆\n",
    "λ is a scalar (the eigenvalue). This equation implies that when matrix \n",
    "𝐴\n",
    "A acts on vector \n",
    "𝑣\n",
    "v, it simply scales the vector by \n",
    "𝜆\n",
    "λ.\n",
    "\n",
    "Eigenvectors: The directions that are unchanged (except for scaling) when the matrix transformation is applied.\n",
    "Eigenvalues: The amount by which the eigenvector is stretched or shrunk.\n",
    "Eigen-decomposition is the process of decomposing a matrix into its eigenvalues and eigenvectors. For a matrix \n",
    "𝐴\n",
    "A, if it can be diagonalized, it can be expressed as:\n",
    "\n",
    "𝐴\n",
    "=\n",
    "𝑉\n",
    "Λ\n",
    "𝑉\n",
    "−\n",
    "1\n",
    "A=VΛV \n",
    "−1\n",
    " \n",
    "\n",
    "where \n",
    "𝑉\n",
    "V is the matrix of eigenvectors and \n",
    "Λ\n",
    "Λ is the diagonal matrix of eigenvalues.\n",
    "\n",
    "Example: Let’s consider a 2x2 matrix:\n",
    "\n",
    "𝐴\n",
    "=\n",
    "[\n",
    "4\n",
    "1\n",
    "2\n",
    "3\n",
    "]\n",
    "A=[ \n",
    "4\n",
    "2\n",
    "​\n",
    "  \n",
    "1\n",
    "3\n",
    "​\n",
    " ]\n",
    "\n",
    "To find the eigenvalues, solve \n",
    "det\n",
    "⁡\n",
    "(\n",
    "𝐴\n",
    "−\n",
    "𝜆\n",
    "𝐼\n",
    ")\n",
    "=\n",
    "0\n",
    "det(A−λI)=0, where \n",
    "𝐼\n",
    "I is the identity matrix. The solution gives two eigenvalues, and for each eigenvalue, we solve \n",
    "(\n",
    "𝐴\n",
    "−\n",
    "𝜆\n",
    "𝐼\n",
    ")\n",
    "𝑣\n",
    "=\n",
    "0\n",
    "(A−λI)v=0 to find the corresponding eigenvector.\n",
    "\n",
    "## Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "Eigen-decomposition is the factorization of a square matrix into a set of eigenvectors and eigenvalues. It allows us to express a matrix \n",
    "𝐴\n",
    "A as:\n",
    "\n",
    "𝐴\n",
    "=\n",
    "𝑉\n",
    "Λ\n",
    "𝑉\n",
    "−\n",
    "1\n",
    "A=VΛV \n",
    "−1\n",
    " \n",
    "\n",
    "where \n",
    "𝑉\n",
    "V is the matrix of eigenvectors, \n",
    "Λ\n",
    "Λ is the diagonal matrix of eigenvalues, and \n",
    "𝑉\n",
    "−\n",
    "1\n",
    "V \n",
    "−1\n",
    "  is the inverse of \n",
    "𝑉\n",
    "V.\n",
    "\n",
    "Eigen-decomposition is significant because it simplifies matrix operations, such as computing powers of matrices, solving differential equations, and diagonalizing matrices for applications like PCA. It gives insight into the structure of a matrix and reveals the directions (eigenvectors) and magnitudes (eigenvalues) in which the matrix acts on vectors.\n",
    "\n",
    "## Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "A square matrix \n",
    "𝐴\n",
    "A is diagonalizable if and only if it has a complete set of linearly independent eigenvectors. This means there must be \n",
    "𝑛\n",
    "n linearly independent eigenvectors for an \n",
    "𝑛\n",
    "×\n",
    "𝑛\n",
    "n×n matrix.\n",
    "\n",
    "Condition:\n",
    "\n",
    "The matrix must have distinct eigenvalues or repeated eigenvalues with a sufficient number of independent eigenvectors.\n",
    "The geometric multiplicity (the number of independent eigenvectors associated with each eigenvalue) must equal the algebraic multiplicity (the number of times the eigenvalue appears in the characteristic equation).\n",
    "Proof (Sketch): If \n",
    "𝐴\n",
    "A has \n",
    "𝑛\n",
    "n linearly independent eigenvectors, they can be arranged as columns of a matrix \n",
    "𝑉\n",
    "V. The diagonal matrix \n",
    "Λ\n",
    "Λ contains the eigenvalues. The matrix \n",
    "𝐴\n",
    "A can be diagonalized as \n",
    "𝐴\n",
    "=\n",
    "𝑉\n",
    "Λ\n",
    "𝑉\n",
    "−\n",
    "1\n",
    "A=VΛV \n",
    "−1\n",
    " . If there are not enough independent eigenvectors, the matrix cannot be diagonalized.\n",
    "\n",
    "## Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.\n",
    "The spectral theorem states that any real symmetric matrix can be diagonalized by an orthogonal matrix of its eigenvectors. In other words, for a real symmetric matrix \n",
    "𝐴\n",
    "A, there exists an orthogonal matrix \n",
    "𝑉\n",
    "V such that:\n",
    "\n",
    "𝐴\n",
    "=\n",
    "𝑉\n",
    "Λ\n",
    "𝑉\n",
    "𝑇\n",
    "A=VΛV \n",
    "T\n",
    " \n",
    "\n",
    "This means \n",
    "𝐴\n",
    "A can be expressed as a diagonal matrix in an orthogonal basis, where the diagonal elements are the eigenvalues.\n",
    "\n",
    "Significance:\n",
    "\n",
    "The spectral theorem ensures that real symmetric matrices have real eigenvalues and can be orthogonally diagonalized.\n",
    "It simplifies matrix operations like finding powers, solving differential equations, and understanding the geometric properties of the matrix.\n",
    "Example: If \n",
    "𝐴\n",
    "=\n",
    "[\n",
    "2\n",
    "1\n",
    "1\n",
    "2\n",
    "]\n",
    "A=[ \n",
    "2\n",
    "1\n",
    "​\n",
    "  \n",
    "1\n",
    "2\n",
    "​\n",
    " ], it can be diagonalized as \n",
    "𝐴\n",
    "=\n",
    "𝑉\n",
    "Λ\n",
    "𝑉\n",
    "𝑇\n",
    "A=VΛV \n",
    "T\n",
    " , where \n",
    "𝑉\n",
    "V is orthogonal and \n",
    "Λ\n",
    "Λ is the diagonal matrix of eigenvalues.\n",
    "\n",
    "## Q5. How do you find the eigenvalues of a matrix and what do they represent?\n",
    "Eigenvalues are found by solving the characteristic equation:\n",
    "\n",
    "det\n",
    "⁡\n",
    "(\n",
    "𝐴\n",
    "−\n",
    "𝜆\n",
    "𝐼\n",
    ")\n",
    "=\n",
    "0\n",
    "det(A−λI)=0\n",
    "\n",
    "where \n",
    "𝐴\n",
    "A is the matrix, \n",
    "𝜆\n",
    "λ is the eigenvalue, and \n",
    "𝐼\n",
    "I is the identity matrix. The determinant gives a polynomial equation in \n",
    "𝜆\n",
    "λ, and solving this equation provides the eigenvalues.\n",
    "\n",
    "Eigenvalues represent how much the matrix stretches or shrinks its eigenvectors when applied to them. They indicate the scaling factor in the direction of the eigenvectors.\n",
    "\n",
    "## Q6. What are eigenvectors and how are they related to eigenvalues?\n",
    "Eigenvectors are non-zero vectors that remain in the same direction after a linear transformation represented by a matrix. The only change to an eigenvector after transformation is that it is scaled by a corresponding eigenvalue.\n",
    "\n",
    "The relationship between eigenvectors and eigenvalues is given by:\n",
    "\n",
    "𝐴\n",
    "𝑣\n",
    "=\n",
    "𝜆\n",
    "𝑣\n",
    "Av=λv\n",
    "\n",
    "where \n",
    "𝐴\n",
    "A is the matrix, \n",
    "𝑣\n",
    "v is the eigenvector, and \n",
    "𝜆\n",
    "λ is the corresponding eigenvalue.\n",
    "\n",
    "## Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?\n",
    "Geometrically, eigenvectors represent the directions in which the linear transformation (matrix) scales vectors, while eigenvalues represent the scaling factors.\n",
    "\n",
    "If \n",
    "𝜆\n",
    "=\n",
    "1\n",
    "λ=1, the eigenvector is unchanged in magnitude but maintains its direction.\n",
    "If \n",
    "𝜆\n",
    ">\n",
    "1\n",
    "λ>1, the eigenvector is stretched.\n",
    "If \n",
    "0\n",
    "<\n",
    "𝜆\n",
    "<\n",
    "1\n",
    "0<λ<1, the eigenvector is shrunk.\n",
    "If \n",
    "𝜆\n",
    "<\n",
    "0\n",
    "λ<0, the vector is reflected and scaled.\n",
    "\n",
    "## Q8. What are some real-world applications of eigen decomposition?\n",
    "Applications of eigen decomposition include:\n",
    "\n",
    "Principal Component Analysis (PCA): Eigen decomposition is used to identify the directions of maximum variance in high-dimensional data.\n",
    "Vibration Analysis: Eigenvalues represent natural frequencies, and eigenvectors represent the mode shapes of vibrating systems.\n",
    "Quantum Mechanics: Eigenvalues correspond to observable quantities, and eigenvectors represent states in quantum systems.\n",
    "Graph Theory: The eigenvalues of the adjacency matrix of a graph provide insights into the structure and properties of the graph.\n",
    "\n",
    "## Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?\n",
    "Yes, a matrix can have multiple eigenvectors corresponding to the same eigenvalue (this is known as the geometric multiplicity of the eigenvalue). If the eigenvalue has a geometric multiplicity greater than 1, it has more than one independent eigenvector.\n",
    "\n",
    "For distinct eigenvalues, the matrix will have distinct eigenvectors. For repeated eigenvalues, the matrix can have one or more eigenvectors depending on its diagonalizability.\n",
    "\n",
    "## Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning? Discuss at least three specific applications or techniques that rely on Eigen-Decomposition.\n",
    "Principal Component Analysis (PCA): PCA relies on eigen decomposition of the covariance matrix to find the principal components, which are the directions of maximum variance in the data. It is widely used for dimensionality reduction and noise reduction.\n",
    "Spectral Clustering: Eigen decomposition of the Laplacian matrix of a graph is used to identify clusters in the data based on graph structure.\n",
    "Latent Semantic Analysis (LSA): In natural language processing, eigen decomposition is used to reduce the dimensionality of document-term matrices, capturing the latent semantic structure of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d05ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
